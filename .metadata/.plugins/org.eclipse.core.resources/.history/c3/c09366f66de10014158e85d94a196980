package com.hdfs;

import java.io.BufferedWriter;
import java.io.File;
import java.io.FileWriter;
import java.io.IOException;
import java.lang.reflect.Method;
import java.net.URL;
import java.net.URLClassLoader;
import java.util.ArrayList;
import java.util.LinkedHashMap;

public class ReducerThread extends Thread {

	public Thread t;
	String reducerThreadName;
	Integer taskId;
	TaskTrackerConfiguration tTCnf;
	LinkedHashMap<Integer, ReducerTaskDetail> mapRunningRedcuerIdToTaskInfo;

	public ReducerThread(
			String reducerThreadNam,
			LinkedHashMap<Integer, ReducerTaskDetail> mapRunningRedcuerIdToTaskI,
			TaskTrackerConfiguration taskTrackerConfiguration, Integer taskI) {
		reducerThreadName = reducerThreadNam;
		taskId = taskI;
		mapRunningRedcuerIdToTaskInfo = mapRunningRedcuerIdToTaskI;
		tTCnf = taskTrackerConfiguration;
	}

	@Override
	public void run() {
		performReduceTask();
	}

	private void performReduceTask() {
		System.out.println("*********Reduce Task " + taskId
				+ " Started************");
		HDFSMethods hdfsMethods = new HDFSMethods(tTCnf);

		Integer jobId = mapRunningRedcuerIdToTaskInfo.get(taskId).jobId;
		ArrayList<String> mapOutputFilesToBeReduced = mapRunningRedcuerIdToTaskInfo
				.get(taskId).mapOutputFilesToBeReduced;
		String outputFileName = mapRunningRedcuerIdToTaskInfo.get(taskId).outputFile;
		String reducerName = mapRunningRedcuerIdToTaskInfo.get(taskId).reducerName;

		String reducerOutputFileName = outputFileName + "_" + jobId + "_"
				+ taskId;

		try {
			BufferedWriter bufferedWriter = new BufferedWriter(new FileWriter(
					tTCnf.reducedFilesLocation + "\\" + reducerOutputFileName,
					true));
			for (String fileToBeReduced : mapOutputFilesToBeReduced) {
				String fileContent = hdfsMethods
						.readRemoteFile(fileToBeReduced);
				String reducedOutputContent = startReduceTask(reducerName,
						fileContent);
				bufferedWriter.write(reducedOutputContent + "\n");
			}
			bufferedWriter.close();
		} catch (IOException e) {
			e.printStackTrace();
		}

		// write file in hdfs
		hdfsMethods.writeRemoteFile(reducerOutputFileName,
				tTCnf.reducedFilesLocation);

		System.out.println("Reducer Output File Name: " + outputFileName);

		synchronized (mapRunningRedcuerIdToTaskInfo) {
			mapRunningRedcuerIdToTaskInfo.get(taskId).taskCompleted = true;
		}
		synchronized (tTCnf) {
			tTCnf.freeReduceSlots++;
		}

		System.out.println("*********Reduce Task " + taskId
				+ " Done**************");
	}

	private String startReduceTask(String reducerName, String inputContent) {
		String outputFileContent = null;
		String output = null;
		File jarDir = new File(tTCnf.jarFilesPath);
		String className = mapName;

		for (File jarFile : jarDir.listFiles()) {
			try {
				URL fileURL = jarFile.toURI().toURL();
				String jarURL = "jar:" + fileURL + "!/";
				URL urls[] = { new URL(jarURL) };
				URLClassLoader ucl = new URLClassLoader(urls);
				Class cls = Class.forName(className, true, ucl);
				Object obj = cls.newInstance();
				Class params[] = new Class[1];
				params[0] = String.class;
				Method m = cls.getDeclaredMethod("map", params);
				output = (String) m.invoke(obj, inputContent);
				break;
			} catch (Exception e) {
				e.printStackTrace();
			}
		}
		return output;
		return outputFileContent;
	}

	public void start() {
		System.out.println("Starting Reducer Thread:" + reducerThreadName);

		if (t == null) {
			t = new Thread(this, reducerThreadName);
			t.start();
		}
	}
}
